# Database Batch Source


Description
-----------
Reads from a database using a configurable SQL query.
Outputs one record for each row returned by the query.


Use Case
--------
The source is used whenever you need to read from a database. For example, you may want
to create daily snapshots of a database table by using this source and writing to
a TimePartitionedFileSet.


Properties
----------

**Reference Name:** This is a unique name used to identify this source for lineage, annotating metadata, so on.

**Plugin Name:** This is the name of the JDBC plugin defined in the JSON file.

**Plugin Type:** This is the type of the JDBC plugin defined in the JSON file. The default value is to 'jdbc'.

**Connection String:** This is the JDBC connection string including database name. (Macro-enabled)

**Import Query:** Use the SELECT query to import the data from the specified table. 
You can import all or arbitrary number of columns using \*. The Query should contain the '$CONDITIONS' string. 
For example, 'SELECT * FROM table WHERE $CONDITIONS'.
The '$CONDITIONS' string will be replaced by 'splitBy' field limits specified by the bounding query.
The '$CONDITIONS' string is not required if numSplits is set to 1. (Macro-enabled)

**Bounding Query:** This query must return the minimum and maximum of the values of the 'splitBy' field.
For example, 'SELECT MIN(id),MAX(id) FROM table'. This property is not required if numSplits is set to 1. (Macro-enabled)

**Split-By Field Name:** These are the field names used to generate splits. This property is not required if numSplits is set to 1. (Macro-enabled)

**Number of Splits to Generate:** This is the value for number of splits to generate. (Macro-enabled)

**Username:** Use this for connecting to the specified database. This is required for databases that need
authentication and optional for databases that do not require authentication. (Macro-enabled)

**Password:** Use this for connecting to the specified database. This is required for databases that need
authentication and optional for databases that do not require authentication. (Macro-enabled)

**Connection Arguments:** A list of arbitrary string tag/value pairs as connection arguments. These arguments are passed to the JDBC driver for additional configurations as connection arguments. This is a semicolon-separated list of key-value pairs, where each pair is separated by a equals '=' and specifies the key and value for the argument. 
For example, 'key1=value1;key2=value2' states that the 'key1' is mapped to 'value1' and 'key2' is mapped to 'value2'. (Macro-enabled)

**Enable Auto-Commit:** Use this to enable auto-commit for queries. The default value is 'false'. This property is only useful when a jdbc driver does not support a false value for autocommit or throws an error when auto-commit is set to false. To resolve this, set the value to 'true'.

**Column Name Case:** Sets the case of the column names returned from the query.
Possible options are ``upper`` or ``lower``. By default or for any other input, the column names are not modified and
the names returned from the database are used as-is. Note that setting this property provides predictability
of column name cases across different databases but might result in column name conflicts (if multiple column
names are the same) when the case is ignored (optional).

**Transaction Isolation Level:** Use this sink to run the transaction isolation level for queries. the default value is TRANSACTION_SERIALIZABLE. See java.sql.Connection#setTransactionIsolation for more details. The jdbc driver shows an exception if the database does not have transactions enabled and this property is set to True. To resolve this, set this property to TRANSACTION_NONE.

**Schema:** This is the schema of the output records generated by this source. Use this schema to replace the schema returned from the query. 
Note: this schema must match with the schema returned from the query where the schema field can be nullable and contains a subset of the fields.


Example
-------
This example connects to a database using the specified 'connectionString', which means
it will connect to the 'test' database of a PostgreSQL instance running on 'localhost'.
It will run the 'importQuery' against the 'users' table to read four columns from the table.
The column types will be used to derive the record field types output by the source.

    {
        "name": "Database",
        "type": "batchsource",
        "properties": {
            "jdbcPluginName": "psql",
            "jdbcPluginType": "jdbc",
            "importQuery": "select id,name,email,phone from users where $CONDITIONS",
            "boundingQuery": "select min(id),max(id) from users",
            "splitBy": "id",
            "connectionString": "jdbc:postgresql://localhost:5432/test",
            "user": "user123",
            "password": "password-abc"
        }
    }

For example, if the 'id' column is a primary key of type int and the other columns are
non-nullable varchars, output records will have the following schema:

    +======================================+
    | field name     | type                |
    +======================================+
    | id             | int                 |
    | name           | string              |
    | email          | string              |
    | phone          | string              |
    +======================================+

## Notes :

`List of supported drivers and connection details`

```
+=====================================================================================================+
| DB name  | Driver Name(class name)          |   Database URL & Example                              |
+=====================================================================================================+
| MySQL    | com.mysql.jdbc.Driver            |   jdbc:mysql://<server>:<port>/<databaseName>         |
                                                  Eg: jdbc:mysql://localhost:3306/myDBName

| Postgres | org.postgresql.Driver            |   jdbc:postgresql://<server>:<port>/<databaseName>    |
                                                  Eg: jdbc:postgresql://localhost:5432/myDBName

| H2DB     | org.h2.Driver                    |   jdbc:h2:tcp://<server>:<port>/<databasePath>        |
                                                  Eg: jdbc:h2:tcp://192.168.111.139:9092/~/test

| Oracle   | oracle.jdbc.driver.OracleDriver  |   jdbc:oracle:thin:@<host>:<port>/<serviceName>       |
                                                  Eg: jdbc:oracle:thin:@localhost:1521/orcls
+=====================================================================================================+
```

Transaction Isolation Level supports for listed dbs:

***MySql/Postgres*** :  "TRANSACTION_READ_UNCOMMITTED", "TRANSACTION_READ_COMMITTED","TRANSACTION_REPEATABLE_READ",
                        "TRANSACTION_SERIALIZABLE (default)" .

### Steps to upload database driver

In order to use this accelerator to connect supported databases, it is mandatory to upload corresponding driver in cdap (if not already existing).

Driver jar can be downloaded from internet. Please refer to the following table for tested driver versions:

```
+===========================+
| DB name  | Driver Version |
+===========================+
| MySQL    | 8.0.18         |
| Postgres | 9.4.1211       |
| H2DB     | 1.4.200        |
| Oracle   | 12.1.0.2       |
+===========================+
```

* Copy driver jar at any location on one of the cdap master node. For example, copy `postgresql-9.4.1211.jar` in `/tmp` folder.
* Create a json file with the following content and copy it in the same directory used in preceding step.
* Name of the json file should be same as jar file with extension `.json`. For example, `postgresql-9.4.1211.json`
```
{
 "plugins": [
    {
      "name": "<Driver Name>",
      "type": "jdbc",
      "description": <Driver description>",
      "className": "<Driver Class>"
    }
  ]
}
```

**For Example:** for psql content of json file

```
{
 "plugins": [
    {
      "name": "psql",
      "type": "jdbc",
      "description": "Postgres JDBC external plugin",
      "className": "org.postgresql.Driver"
    }
  ]
}
```
* Login to one of cdap master node
* Go to directory `/opt/cdap/master`
* Run the command `./bin/cdap cli -v false`
* Enter the username and password when prompted
* Run the command to load driver
`load artifact <driver-jar-path> config-file <json-path> name <connector-name> version <driver-version>`
<br/> **For example:** 
`load artifact /tmp/postgresql-9.4.1211.jar config-file /tmp/postgresql-9.4.1211.json name psql-connector-java version 9.4.1211`

* The following rest API can be used to verify the success of driver upload<br/>
`namespaces/default/artifacts/psql-connector-java/versions/9.4.1211`
<br/> **Expected output**

```
{
  "classes": {
    "apps": [],
    "plugins": [
      {
        "type": "jdbc",
        "name": "psql",
        "description": "Postgres JDBC external plugin",
        "className": "org.postgresql.Driver",
        "properties": {},
        "endpoints": [],
        "requirements": {
          "datasetTypes": []
        }
      }
    ]
  },
  "properties": {},
  "parents": [],
  "name": "psql-connector-java",
  "version": "9.4.1211",
  "scope": "USER"
}
```
